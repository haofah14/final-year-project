## ðŸš€ Catalyzing Content Generation and Automation: Empowering Diverse Written Content Creation through Generative AI 

This repository hosts a comprehensive research project and practical implementation exploring how Generative AI can empower the creation of diverse written content. The project systematically evaluates powerful language models like GPT-2, GPT-Neo, and OPT-125m, focusing on automated creativity assessment and practical deployment through an intuitive web application.

### ðŸŒŸ Project Overview

Title: Catalyzing Content Generation and Automation: Empowering Diverse Written Content Creation through Generative AI

Conducted by: Lam Hao Fah

Supervisor: Dr. Owen Noel Newton Fernando

Institution: School of Computing and Data Science, Nanyang Technological University, Singapore

This research addresses key limitations of traditional content creation by harnessing the capabilities of large language models (LLMs), evaluating their creative potential systematically, and demonstrating real-world applications through an interactive web prototype.

### ðŸ“‚ Project Structure

```
.
â”œâ”€â”€ web_app/                        # Web application prototype
â”‚   â”œâ”€â”€ backend/                    # Flask backend service
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ .env                    # Environment variables
â”‚   â”‚   â”œâ”€â”€ .gitignore
â”‚   â”‚   â”œâ”€â”€ app.py                 # Backend API endpoints
â”‚   â”‚   â”œâ”€â”€ functions.py           # Utility functions for backend
â”‚   â”‚   â””â”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ frontend/                   # React frontend interface
â”‚   â”‚   â”œâ”€â”€ node_modules/
â”‚   â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ .gitignore
â”‚   â”‚   â”œâ”€â”€ package-lock.json
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ README.md                   # README for the web_app module
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                       # Main project documentation
â”œâ”€â”€ gpt-2-model.ipynb               # GPT-2 training notebook
â”œâ”€â”€ gpt-neo-model.ipynb             # GPT-Neo training notebook
â”œâ”€â”€ my_dataset.csv                  # Dataset used for training
â””â”€â”€ opt-model.ipynb                 # OPT-125 training notebook
```

### ðŸ›  Model Weights

Due to size limitations, the model weights are hosted on Hugging Face.
```
https://huggingface.co/haofah14/models
```